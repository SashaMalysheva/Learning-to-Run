import numpy as np
import gym

from keras.models import Sequential, Model
from keras.layers import Dense, Activation, Flatten, Input, merge
from keras.optimizers import Adam

from osim.env import RunEnv

from rl.agents import DDPGAgent
from rl.memory import SequentialMemory
from rl.random import OrnsteinUhlenbeckProcess

env = RunEnv(visualize = False)
observation = env.reset(difficulty = 0)
total_reward = 0
for j in range(10):
    for i in range(10000):
        observation, reward, done, info = env.step(env.action_space.sample())
        total_reward += reward
        if done:
            break
    print "total reward: ", total_reward
